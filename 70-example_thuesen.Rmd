# Ex: Ventricular Shortening Velocity

![](images/common/ISwR_thuesen.PNG)

```{r, include=FALSE}
knitr::opts_chunk$set(comment     = "",
                      echo        = TRUE, 
                      warning     = FALSE, 
                      message     = FALSE,
                      fig.align   = "center", # center all figures
                      fig.width   = 6,        # set default figure width to 4 inches
                      fig.height  = 4)        # set default figure height to 3 inches
```

```{r, comment=FALSE, message=FALSE}
library(tidyverse)       # super helpful everything!
library(magrittr)        # includes other versions of the pipe 
library(haven)           # inporting SPSS data files
library(furniture)       # nice tables of descriptives
library(texreg)          # nice regression summary tables
library(stargazer)       # nice tables of descrip and regression
library(corrplot)        # visualize correlations
library(car)             # companion for applied regression
library(effects)         # effect displays for models
library(psych)           # lots of handy tools
library(ISwR)            # Introduction to Statistics with R (datasets)
```

## Purpose

### Research Question

> Is there a relationship between fasting blood flucose and shortening of ventricular velocity among type 1 diabetic patiences?  If so, what is the nature of the association?


### Data Description

This dataset is included in the `ISwR` package [@R-ISwR], which was a companion to the texbook "Introductory Statistics with R, 2nd ed." [@dalgaard2008], although it was first published by @altman1991 in table 11.6. 


> The `thuesen` data frame has 24 rows and 2 columns. It contains ventricular shortening velocity and blood glucose for type 1 diabetic patients.

* `blood.glucose` a numeric vector, fasting blood glucose (mmol/l).
* `short.velocity` a numeric vector, mean circumferential shortening velocity (%/s).


```{r}
data(thuesen, package = "ISwR")

tibble::glimpse(thuesen)  # view the class and 1st few values of each variable
```


## Exploratory Data Analysis

```{block type='rmdimportant', echo=TRUE}
Before embarking on any inferencial anlaysis or modeling, always get familiar with your variables one at a time *(univariate)*, as well as pairwise *(bivariate)*.
```

### Univariate Statistics

Summary Statistics for all three variables of interest

```{r, results='asis'}
thuesen %>% 
  stargazer::stargazer(type = "html")
```

The `stargazer()` function has many handy options, should you wish to change the default settings.

```{r, results="asis"}
thuesen %>% 
  stargazer::stargazer(type   = "html", 
                       digits = 4, 
                       flip   = TRUE,                    
                       summary.stat   = c("n", "mean", "sd", "min", "median", "max"),
                       title  = "Descriptives")
```

Although the `table1()` function from the `furniture` package creates a nice summary table, it 'hides' the nubmer of missing values for each continuous variable [@R-furniture].

```{r}
thuesen %>% 
  furniture::table1("Fasting Blood Glucose" = blood.glucose, 
                    "Circumferential Shortening Velocity" = short.velocity,  # defaults to excluding any row missing any variable
                    output = "html")
```


```{r}
thuesen %>% 
  furniture::table1("Fasting Blood Glucose" = blood.glucose, 
                    "Circumferential Shortening Velocity" = short.velocity,
                    na.rm = FALSE,     # retains even partial cases
                    output = "html")
```


### Univariate Visualizations

```{r}
ggplot(thuesen,
       aes(blood.glucose)) +        # variable of interest (just one)
  geom_histogram(binwidth = 2)      # specify the width of the bars
```


```{r}
thuesen %>% 
  ggplot() +
  aes(short.velocity) +              # variable of interest (just one)
  geom_histogram(bins = 10)          # specify the number of bars
```



### Bivariate Statistics (Unadjusted Pearson's correlation)

The `cor()` fucntion in base $R$ doesn't like `NA` or missing values

```{r}
thuesen %>% cor()           
```

```{block type='rmdlightbulb', echo=TRUE}
You may specify how to handle cases that are missing on at least one of the variables of interest:

* `use = "everything"` `NA`s will propagate conceptually, i.e., a resulting value will be `NA` whenever one of its contributing observations is `NA` **<-- DEFAULT**
* `use = "all.obs"` the presence of missing observations will produce an error
* `use = "complete.obs"` missing values are handled by casewise deletion (and if there are no complete cases, that gives an error). 
* `use = "na.or.complete"` is the same as above unless there are no complete cases, that gives `NA` 
* `use = "pairwise.complete.obs"` the correlation between each pair of variables is computed using all complete pairs of observations on those variables. This can result in covariance matrices which are not positive semi-definite, as well as `NA` entries if there are no complete pairs for that pair of variables. 
```

Commonly, we want  **listwise deletion**:

```{r}
thuesen %>% cor(use = "complete.obs")   # list-wise deletion
```



It is also handy to specify the  number of decimal places desired, but adding a rounding step:

```{r}
thuesen %>% 
  cor(use = "complete.obs") %>%   
  round(2)                       # number od decimal places
```


If you desire a correlation single value of a single PAIR of variables, instead of a matrix, then you must use a **`magrittr` exposition pipe (`%$%`)** 

```{r}
thuesen %$%                            # notice the special kind of pipe
  cor(blood.glucose, short.velocity,   # specify exactly TWO variables            
      use = "complete.obs")
```

In addition to the `cor()` funciton, the base $R$ `stats` package also includes the `cor.test()` function to test if the correlation is zero ($H_0: R = 0$)

This TESTS if the cor == 0
```{r}
thuesen %$%                                 # notice the special kind of pipe
  cor.test(blood.glucose, short.velocity,   # specify exactly TWO variables            
           use="complete.obs")
```


The default correltaion type for `cor()`is **Pearson's $R$**, which assesses linear relationships.  **Spearman's correlation** assesses monotonic relationships.

```{r}
thuesen %$%                            # notice the special kind of pipe
  cor(blood.glucose, short.velocity,   # specify exactly TWO variables  
      use    = 'complete',
      method = 'spearman')       # spearman's (rho) 
```


```{r}
thuesen %>% 
  dplyr::select(blood.glucose, short.velocity) %>% 
  furniture::tableC(cor_type = "pearson",
                    na.rm = TRUE,
                    rounding = 3,
                    output = "markdown",
                    booktabs = TRUE,
                    caption = "Correlation Table")
```



### Bivariate Visualization

Scatterplots show the relationship between two continuous measures (one on the $x-axis$ and the other on the $y-axis$), with one point for each observation.

```{r, eval=FALSE}
ggplot(thuesen, 
       aes(x = blood.glucose,        # x-axis variable
           y = short.velocity)) +    # y-axis variable
  geom_point() +                     # place a point for each observation
  theme_bw()                         # black-and-white theme 
```

Both the code chunk above and below produce the same plot.

```{r}
thuesen %>% 
  ggplot() +
  aes(x = blood.glucose,         # x-axis variable
      y = short.velocity) +     # y-axis variable
  geom_point() +                 # place a point for each observation
  theme_bw()                     # black-and-white theme 
```






## Regression Analysis


### Fit A Simple Linear Model


$$
Y = \beta_0 + \beta_1 \times X
$$


```{block type='rmdlightbulb', echo=TRUE}
The `lm()` function must be supplied with at least two options:

* a formula:  `Y ~ X`
* a dataset: `data = XXXXXXX`

When a model is fit and directly saved as a named object via the assignment opperator (`<-`), no output is produced.
```

* `short.velocity` dependent variable or outcome ($Y$)
* `blood.glucose` independent variable or predictor ($X$)



```{r}
fit_vel_glu <- lm(short.velocity ~ blood.glucose, 
                  data = thuesen)
```


Running the name of the fit object yields very little output:

```{r}
fit_vel_glu
```


Appling the `summary()` function produced a good deal more output:

```{r}
summary(fit_vel_glu)
```

You may request specific pieces of the output:

* Coefficients or beta estimates:

```{r}
coef(fit_vel_glu)
```

* 95% confidence intervals for the coefficients or beta estimates:

```{r}
confint(fit_vel_glu)
```

* The F-test for overall modle fit vs. a $null$ or empty model having only an intercept and no predictors.

```{r}
anova(fit_vel_glu)
```

* Various other model fit indicies:


```{r}
logLik(fit_vel_glu)     
AIC(fit_vel_glu)
BIC(fit_vel_glu)
```


### Checking Assumptions via Residual Diagnostics

```{block type='rmdimportant', echo=TRUE}
Before reporting a model, ALWAYS make sure to check the residules to ensure that the model assumptions are not violated.
```


```{r}
plot(fit_vel_glu, which = 1)
```

```{r}
plot(fit_vel_glu, which = 2)
```

```{r}
plot(fit_vel_glu, which = 5)
```

```{r}
plot(fit_vel_glu, which = 6)
```




Viewing potentially influential or outlier points based on plots above:

```{r}
thuesen %>% 
  dplyr::mutate(id = row_number()) %>% 
  dplyr::filter(id == c(13, 20, 24))
```

The `car` package has a handy function called `residualPlots()` for displaying residual plots quickly [@R-car].

```{r}
car::residualPlots(fit_vel_glu)
```


Here is a fancy way to visulaize 'potential problem cases' with `ggplot2`:

```{r}
thuesen %>% 
  dplyr::filter(complete.cases(.)) %>%                # keep only complete cases
  ggplot() +                                          # name the FULL dataset 
  aes(x = blood.glucose,                              # x-axis variable name
      y = short.velocity) +                           # y-axis variable name
  geom_point() +                                      # do a scatterplot
  stat_smooth(method = "lm") +                        # smooth: linear model
  theme_bw()  +                                       # black-and-while theme
  geom_point(data = thuesen %>%                       # override the dataset from above
               filter(row_number() == c(13, 20, 24)), # with a reduced subset of cases
             size = 4,                                # make the points bigger in size 
             color = "red")                           # give the points a different color
```


### Manually checking residual diagnostics

You may extract values from the model in dataset form and then you can maually plot the residuals.

```{r}
thuesen %>% 
  dplyr::filter(complete.cases(.)) %>%            # keep only complete cases
  dplyr::mutate(pred = fitted(fit_vel_glu)) %>%   # fitted/prediction values
  dplyr::mutate(resid = residuals(fit_vel_glu))   # residual values
```

Check for equal spread of points along the $y=0$ horizontal line: 

```{r}
thuesen %>% 
  dplyr::mutate(id = row_number()) %>% 
  dplyr::filter(complete.cases(.)) %>%                # keep only complete cases
  dplyr::mutate(pred = fitted(fit_vel_glu)) %>%       # fitted/prediction values
  dplyr::mutate(resid = residuals(fit_vel_glu)) %>%   # residual values
  ggplot() +
  aes(x = id,
      y = resid) +
  geom_point() +
  geom_hline(yintercept = 0,
             color = "red",
             size = 1,
             linetype = "dashed") +
  theme_classic() +
  labs(title = "Looking for homogeneity of residuals",
       subtitle = "want to see equal spread all across")
```


Check for normality:

```{r}
thuesen %>% 
  dplyr::filter(complete.cases(.)) %>%                # keep only complete cases
  dplyr::mutate(pred = fitted(fit_vel_glu)) %>%       # fitted/prediction values
  dplyr::mutate(resid = residuals(fit_vel_glu)) %>%   # residual values
  ggplot() +
  aes(resid) +
  geom_histogram(bins = 12,
                 color = "blue",
                 fill = "blue",
                 alpha = 0.3) +
  geom_vline(xintercept = 0,
             size = 1,
             color = "red",
             linetype = "dashed") +
  theme_classic() +
  labs(title = "Looking for normality of residuals",
       subtitle = "want to see roughly a bell curve")
```









## Conclusion


### Tabulate the Final Model Summary

You may also present the output in a table using two different packages:

* The `stargazer` package has `stargazer()` function:

```{r, results='asis'}
stargazer::stargazer(fit_vel_glu, type = "html")
```


```{block type='rmdlightbulb', echo=TRUE}
The `stargazer` package can produce the regression table in various output types:  

* `type = "latex` **Default**  Use when knitting your .Rmd file to a .pdf via LaTeX
* `type = "text` **Default**  Use when working on a project and viewing tables on your computer screen
* `type = "html` **Default**  Use when knitting your .Rmd file to a .html document
```

* The `texreg` package has the `texreg()` fucntion:

```{r, results="asis"}
texreg::htmlreg(fit_vel_glu)
```


```{block type='rmdlightbulb', echo=TRUE}
The `texreg` package contains three version of the regression table function.  

* `screenreg()` Use when working on a project and viewing tables on your computer screen
* `htmlreg()` Use when knitting your .Rmd file to a .html document 
* `texreg()` Use when knitting your .Rmd file to a .pdf via LaTeX
```




### Plot the Model


```{block type='rmdimportant', echo=TRUE}
When a model only contains main effects, a plot is not important for interpretation, but can help understand the relationship between multiple predictors.
```

```{block type='rmdlightbulb', echo=TRUE}
The `Effect()` function from the `effects` package chooses '5 or 6 nice values' for your continuous independent variable ($X$) based on the range of values found in the dataset on which the model was fit and plugs them into the regression equation $Y = \beta_0 + \beta_1 \times X$ to compute the predicted *mean* value of the outcome ($Y$) [@R-effects].
```


```{r}
effects::Effect(focal.predictors = c("blood.glucose"),  # IV variable name
                mod = fit_vel_glu)                      # fitted model name
```

You may override the 'nice values' using the `xlevels = list(var_name = c(#, #, ...#)` option.

```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu,
                xlevels = list(blood.glucose = c(5, 10, 15, 20))) 
```

Adding a piped data frame step (` %>% data.frame()`) will arrange the predicted $Y$ values into a column called `fit`.  This tidy data format is ready for plotting.

```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu) %>% 
  data.frame() 
```



```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu,
                xlevels = list(blood.glucose = c(5, 12, 20))) %>% 
  data.frame() %>% 
  ggplot() +
  aes(x = blood.glucose,           # x-axis variable
      y = fit) +                   # y-axis variable
  geom_ribbon(aes(ymin = lower,    # bottom edge of the ribbon
                  ymax = upper),   # top edge of the ribbon
              alpha = .5) +        # ribbon transparency level
  geom_line() +
  theme_bw()
```


Notice that although the regression line is smooth, the ribbon is choppy.  This is because we are basing it on only THREE values of $X$.


```{r}
c(5, 12, 20)
```

Use the `seq()` function in base $R$ to request many values of $X$

```{r}
seq(from = 5, to = 20, by = 5)
```

```{r}
seq(from = 5, to = 20, by = 2)
```

```{r}
seq(from = 5, to = 20, by = 1)
```



```{r}
seq(from = 5, to = 20, by = .5)
```




```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu,
                xlevels = list(blood.glucose = seq(from = 5, to = 20, by = .5))) %>% 
  data.frame() %>% 
  ggplot() +
  aes(x = blood.glucose,           # x-axis variable
      y = fit) +                   # y-axis variable
  geom_ribbon(aes(ymin = lower,    # bottom edge of the ribbon
                  ymax = upper),   # top edge of the ribbon
              alpha = .5) +        # ribbon transparency level
  geom_line() +
  theme_bw()
```

Now that we are basing our ribbon on MANY more points of $X$, the ribbon is much smoother.


For publication, you would of course want to clean up the plot a bit more:



```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu,
                xlevels = list(blood.glucose = seq(from = 5, to = 20, by = .5))) %>% 
  data.frame() %>% 
  ggplot() +
  aes(x = blood.glucose,           # x-axis variable
      y = fit) +                   # y-axis variable
  geom_ribbon(aes(ymin = lower,    # bottom edge of the ribbon
                  ymax = upper),   # top edge of the ribbon
              alpha = .3) +        # ribbon transparency level
  geom_line() +
  theme_bw() +
  labs(x = "Fasting Blood Glucose (mmol/l)",
       y = "Mean Circumferential Shortening Velocity (%/s)")   # axis labels
```



The above plot has a ribbon that represents a 95% confidence interval (`lower` to`upper`) for the MEAN (`fit`) outcome.  Sometimes we would rather display a ribbon for only the MEAN (`fit`) plus-or-minus ONE STANDARD ERROR (`se`) for the mean.  You would do that by changing the variables that define the min and max edges of the ribbon (notice the range of the y-axis has changed):

```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu,
                xlevels = list(blood.glucose = seq(from = 5, to = 20, by = .5))) %>% 
  data.frame() %>% 
  ggplot() +
  aes(x = blood.glucose,           
      y = fit) +                   
  geom_ribbon(aes(ymin = fit - se,    # bottom edge of the ribbon
                  ymax = fit + se),   # top edge of the ribbon
              alpha = .3) +        
  geom_line() +
  theme_bw() +
  labs(x = "Fasting Blood Glucose (mmol/l)",
       y = "Mean Circumferential Shortening Velocity (%/s)")   
```



Of course, you could do both ribbons together:


```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu,
                xlevels = list(blood.glucose = seq(from = 5, to = 20, by = .5))) %>% 
  data.frame() %>% 
  ggplot() +
  aes(x = blood.glucose,           
      y = fit) +                  
  geom_ribbon(aes(ymin = lower,    # bottom edge of the ribbon = lower of the 95% CI
                  ymax = upper),   # top edge of the ribbon = upper of the 95% CI
              alpha = .3) +        
  geom_ribbon(aes(ymin = fit - se,    # bottom edge of the ribbon = mean - SE
                  ymax = fit + se),   # top edge of the ribbon = Mean + SE
              alpha = .3) +        
  geom_line() +
  theme_bw() +
  labs(x = "Fasting Blood Glucose (mmol/l)",
       y = "Mean Circumferential Shortening Velocity (%/s)")   # axis labels
```