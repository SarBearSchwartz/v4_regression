# Ex: Ihno's Experiment 

interaction between two continuous IVs

![](images/common/Ihno_header.PNG)


```{r, include=FALSE}
# set global chunk options...  
#  this changes the defaults so you don't have to repeat yourself
knitr::opts_chunk$set(comment     = NA,
                      cache       = TRUE,
                      echo        = TRUE, 
                      warning     = FALSE, 
                      message     = FALSE, 
                      tab.topcaption = TRUE,
                      ft.topcaption = TRUE, 
                      fig.topcaption = TRUE,
                      tab.align   = "left",
                      ft.align    = "left",  
                      fig.align   = "left", 
                      out.width   = "75%")
```


```{r, comment=FALSE, message=FALSE, warning=FALSE}
# library(remotes)
# remotes::install_github("sarbearschwartz/apaSupp")
# remotes::install_github("ddsjoberg/gtsummary")

library(tidyverse)       
library(haven)   
library(naniar)       
library(apaSupp)
library(corrplot)
library(GGally)
library(performance)
library(interactions)
library(ggResidpanel)
library(car)
```



## PURPOSE

### Research Question


> Does math phobia moderate the relationship between math and statistics performance?  That is, does the assocation between math and stat quiz performance differ at variaous levels of math phobia?


### Data Description


```{block type='rmdlink', echo=TRUE}
Inho's dataset is included in the textbook "Explaining Psychological Statistics" [@epse4] and details regarding the sample and measures is describe in this Encyclopedia's [Vol. 2 - Ihno's Dataset](https://cehs-research.github.io/eBook_explore/example-ihnos-dataset.html).
```

#### Variables

* `statquiz` dependent variable (DV, Y): stat quiz score, max = 10
* `mathquiz` independent variable (IC, X1): prior math quiz score, max = 50
* `phobia`   independent variable (IC, X2): self-reported math phobia, score of 0-10


```{r}
df_ihno <- haven::read_spss("https://raw.githubusercontent.com/CEHS-research/eBook_regression/master/data/Ihno_dataset.sav") %>% 
  haven::zap_widths() %>% 
  haven::zap_label() %>% 
  haven::zap_formats() %>% 
  dplyr::rename_all(tolower) %>% 
  dplyr::mutate(gender = factor(gender, 
                                levels = c(1, 2),
                                labels = c("Female", 
                                           "Male"))) %>% 
  dplyr::mutate(major = factor(major, 
                               levels = c(1, 2, 3, 4,5),
                               labels = c("Psychology",
                                          "Premed",
                                          "Biology",
                                          "Sociology",
                                          "Economics"))) %>% 
  dplyr::mutate(reason = factor(reason,
                                levels = c(1, 2, 3),
                                labels = c("Program requirement",
                                           "Personal interest",
                                           "Advisor recommendation"))) %>% 
  dplyr::mutate(exp_cond = factor(exp_cond,
                                  levels = c(1, 2, 3, 4),
                                  labels = c("Easy",
                                             "Moderate",
                                             "Difficult",
                                             "Impossible"))) %>% 
  dplyr::mutate(coffee = factor(coffee,
                                levels = c(0, 1),
                                labels = c("Not a regular coffee drinker",
                                           "Regularly drinks coffee"))) %>% 
  dplyr::mutate(mathquiz = as.numeric(mathquiz))
```



```{r}
df_ihno %>% 
  dplyr::select(phobia, mathquiz, statquiz) %>% 
  tibble::glimpse()
```



## EXPLORATORY DATA ANALYSIS

```{block type='rmdimportant', echo=TRUE}
Before embarking on any inferential analysis or modeling, always get familiar with your variables one at a time *(univariate)*, as well as pairwise *(bivariate)*.
```





### Univariate Statistics

Center: mean and median
Spread: standard deviation, range (max - min), interquartile range (Q3 - Q1)

```{r test2, label="ihno_desc"}
df_ihno %>% 
  dplyr::select("Math Phobia" = phobia,
                "Math Quiz" = mathquiz,
                "Stat Quiz" = statquiz) %>% 
  apaSupp::tab_desc(caption = "Description of Participants") 
```





### Univariate Visualizations


```{block type='rmdimportant', echo=TRUE}
Always plot your data first!
```

```{r, fig.id="ihno_histo1", fig.cap="Distribution of Self-Reported Math Phobia"}
df_ihno %>% 
  apaSupp::spicy_histos(var = phobia)
```



```{r, fig.id="ihno_histo2", fig.cap="Distribution of Prior Math Quiz Performance"}
df_ihno %>% 
  apaSupp::spicy_histos(var = mathquiz)
```


```{r, fig.id="ihno_histo3", fig.cap="Distribution of Statistics Quiz Performance"}
df_ihno %>% 
  apaSupp::spicy_histos(var = statquiz)
```






### Bivariate Statistics



When two variables are both continuous, correlations (Pearson's $R$) are an important measure of association.  

Notice the discrepancy between the correlation between `statquiz` and `phobia`.  Above, the `psych::pairs.panels()` function uses **pairwise complete** cases by default, so $r=-.39$ is computed on all $n=100$ subjects.  Below, we specified `use = "complete.obs"` in the `cor()` function, so all correlations will be based on the same $n=85$ students, making it **list wise complete**.  The choice of which method to you will vary by situation.


Often it is easier to digest a correlation matrix if it is visually presented, instead of just given as a table of many numbers.  The `corrplot` package has a useful function called `corrplot.mixed()` for doing just that [@R-corrplot].



```{r, fig.id="ihno_corr", fig.cap="Visualize Correlation Matrix"}
df_ihno %>% 
  dplyr::select(phobia, mathquiz, statquiz) %>% 
  cor(use = "complete.obs") %>% 
  corrplot::corrplot.mixed(lower  = "ellipse",
                           upper  = "number",
                           tl.col = "black")
```


```{r, label="ihno_cor"}
df_ihno %>% 
  dplyr::select("Math Phobia" = phobia,
                "Math Quiz" = mathquiz,
                "Stat Quiz" = statquiz) %>% 
  apaSupp::tab_cor(caption = "Correlations")
```



### Bivariate Visualization



```{r, fig.id="ihno_pairs", fig.cap="Pairs Plot"}
df_ihno %>% 
  dplyr::select(phobia, mathquiz, statquiz) %>% 
  data.frame %>% 
  GGally::ggscatmat() +
  theme_bw()
```





```{r, fit.id="ihno_scatter1", fig.cap="Scatterplot for Stat Quiz Regressed on Math Quiz"}
df_ihno %>% 
  ggplot(aes(x = mathquiz,
             y = statquiz)) +
  geom_point() +
  theme_bw() +
  geom_smooth(method = "lm",
              formula = y ~ x) +
  labs(x = "Math Quiz",
       y = "Stat Quiz")
```




```{r, fig.id="ihno_scatter2", fig.cap="Scatterplot for Stat Quiz Regressed on Phobia"}
df_ihno %>% 
  ggplot(aes(x = phobia,
             y = statquiz)) +
  geom_point() +
  theme_bw() +
  geom_smooth(method = "lm",
              formula = y ~ x) +
  labs(x = "Math Phobia",
       y = "Stat Quiz")
```


### Missing Values 

It turns out that 15 of the 100 students did not have a math quiz score recorded.

```{r, fig.id="inho_miss1", fig.cap="Missingness on Each Variable"}
df_ihno %>%
  dplyr::select(mathquiz, statquiz, phobia) %>% 
  naniar::gg_miss_var() +
  theme_bw()
```





## REQRESSION ANALYSIS


* The dependent variable (DV) is Stat Quiz score, `statquiz` ($Y$)

* The independent variables (IVs) are both math quiz score `mathquiz` and math phobia `phobia`($X_1$, $X_2$)

### Subset the Sample


All regression models can only be fit to complete observations regarding the variables included in the model (dependent and independent).  Removing any case that is incomplete with respect to even one variables is called **"list-wise deletion"**.  

In this analysis, models including the `mathquiz` variable will be fit on only 85 students (since 15 students did not take the math quiz), where as models not including this variable will be fit to all 100 students.  

This complicates model comparisons, which require nested models be fit to the same data (exactly).  For this reason, the dataset has been reduced to the subset of students that are complete regarding the three variables utilized throughout the set of five nested models.


```{r}
df_ihno_fitting <- df_ihno %>% 
  dplyr::select(mathquiz, statquiz, phobia) %>% 
  dplyr::filter(complete.cases(mathquiz, statquiz, phobia))
```


```{r}
tibble::glimpse(df_ihno_fitting)
```


### Fit Nested Models 

The **bottom-up** approach consists of starting with an initial `NULL` model with only an intercept term and them building additional models that are nested.  

Two models are considered **nested** if one is contains a subset of the terms (predictors or IV) compared to the other.                                     

```{r}
fit_ihno_lm_0 <- lm(statquiz ~ 1,                 data = df_ihno_fitting)
fit_ihno_lm_1 <- lm(statquiz ~ mathquiz,          data = df_ihno_fitting)
fit_ihno_lm_2 <- lm(statquiz ~ phobia,            data = df_ihno_fitting)
fit_ihno_lm_3 <- lm(statquiz ~ mathquiz + phobia, data = df_ihno_fitting)
fit_ihno_lm_4 <- lm(statquiz ~ mathquiz*phobia,   data = df_ihno_fitting)
```


```{r}
summary(fit_ihno_lm_1)
```


```{r}
summary(fit_ihno_lm_2)
```



```{r}
summary(fit_ihno_lm_3)
```


```{r}
apaSupp::tab_lm(fit_ihno_lm_3)
```




### Comparing Nested Models


#### Model Comparison Table


In single level, multiple linear regression significance of predictors (independent variables, IV) is usually based on both the Wald tests of significance for each beta estimate (shown with stars here) and comparisons in the model fit via the $R^2$ values.


```{r, label="ihno_lms1"}
apaSupp::tab_lms(list(fit_ihno_lm_3, fit_ihno_lm_4)) 
```



```{r, label="ihno_lms2"}
list(fit_ihno_lm_3, fit_ihno_lm_4) %>% 
  apaSupp::tab_lms(mod_names = c("Main Effects", "Moderation"),
                   var_labels = c("mathquiz" = "Math Quiz",
                                  "phobia" = "Math Phobia",
                                  "mathquiz * phobia" = "Quiz X Phobia"),
                   caption = "Multiple Linear Models Regression of Statistics Quiz Performance on Math Phobia and Prior Math Performance",
                   general_note = "Math Phobia was self-reported on a scale of 0 (none) to 10 (max) and the math quiz had a max of 50 points while the statistics quiz had a max of 10 points. NA = not applicable, since variable not included in this model.") 
```


#### Likelihood Ratio Test of Nested Models

An alternative method for determine model fit and variable importance is the likelihood ratio test.  This involves comparing the $-2LL$ or inverse of twice the log of the likelihood value for the model.  The difference in these values follows a Chi Squared distribution with degrees of freedom equal to the difference in the number of parameters estimated *(number of betas)*.

* Test the main effect of math quiz:
```{r}
anova(fit_ihno_lm_0, fit_ihno_lm_1)
```

* Test the main effect of math phobia
```{r}
anova(fit_ihno_lm_0, fit_ihno_lm_2)
```


* Test the main effect of math phobia,  after controlling for math test
```{r}
anova(fit_ihno_lm_1, fit_ihno_lm_3) 
```

* Test the interaction between math test and math phobia (i.e. moderation)
```{r}
anova(fit_ihno_lm_3, fit_ihno_lm_4)
```





### Checking Assumptions via Residual Diagnostics

Before reporting a model, ALWAYS make sure to check the residues to ensure that the model assumptions are not violated.


```{r}
performance::check_residuals(fit_ihno_lm_3)
```

```{r, fig.id="ihno_resid", fig.cap="Residual Diagnostics for Checking Assumptions"}
ggResidpanel::resid_panel(fit_ihno_lm_3)
```


## MULTICOLINEARITY

### Variable Inflation Factors (VIF)

```{r}
car::vif(fit_ihno_lm_3)
```

## CONCLUSION


### Table

Many journals prefer that regression tables include 95% confidence intervals, rater than standard errors for the beta estimates.

```{r, label="ihno_tab2"}
apaSupp::tab_lm(fit_ihno_lm_3,
                var_labels = c("mathquiz" = "Math Quiz",
                               "phobia" = "Math Phobia"),
                caption = "Multiple Linear Models Regression of Statistics Quiz Performance on Math Phobia and Prior Math Performance",
                general_note = "Math Phobia was self-reported on a scale of 0 (none) to 10 (max) and the math quiz had a max of 50 points while the statistics quiz had a max of 10 points. NA = not applicable, since variable not included in this model.") 
```



### Plot

When a model only contains main effects, a plot is not important for interpretation, but can help understand the relationship between multiple predictors.

```{r,}
interactions::interact_plot(model = fit_ihno_lm_3,
                            pred = mathquiz,
                            modx = phobia)
```


Interval = 95% Confidence Interval

```{r}
interactions::interact_plot(model = fit_ihno_lm_3,
                            pred = mathquiz,
                            modx = phobia,
                            modx.values = c(0, 5, 10),
                            interval = TRUE)
```


Interval = plus-or-minus one standard error for the mean (SEM)

```{r}
interactions::interact_plot(model = fit_ihno_lm_3,
                            pred = mathquiz,
                            modx = phobia,
                            modx.values = c(0, 5, 10),
                            interval = TRUE,
                            int.width = .68) +
  theme_bw()
```


The `Effect()` function from the `effects` package chooses '5 or 6 nice values' for each of your continuous independent variable ($X's$) based on the range of values found in the dataset on which the model and plugs all possible combinations of them into the regression equation $Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 \dots \beta_k X_k$ to compute the predicted *mean* value of the outcome ($Y$) [@R-effects].

```{block type='rmdlightbulb', echo=TRUE}
When plotting a regression model the outcome (dependent variable) is always on the y-axis (`fit`) and only one predictor (independent variable) may be used on the x-axis.  You may incorporate additional predictor using colors, shapes, line types, or facets. For these predictors, you will want to specify only 2-4 values for illustration and then declare them as factors prior to plotting.
```





```{r, label="ihno_viz", fig.cap="Statistics Quiz Performance Regressed on Math Phobia and Prior Math Performance"}
effects::Effect(focal.predictors = c("mathquiz", "phobia"),
                mod = fit_ihno_lm_3,
                xlevels = list(phobia = c(0, 5, 10))) %>%   # values for illustration
  data.frame() %>% 
  dplyr::mutate(phobia = factor(phobia,
                                levels = c(0, 5, 10),
                                labels = c(" 0 = minimun",
                                           " 5 = middle",
                                           "10 = maximum"))) %>%               # factor for illustration
  ggplot() +
  aes(x = mathquiz,
      y = fit,
      group = phobia) +
  geom_ribbon(aes(ymin = fit - se, 
                  ymax = fit + se),
              alpha = .15) +
  geom_line(aes(linetype = phobia),
            linewidth = 1) +
  theme_bw() +
  labs(x = "Score on Math Quiz",
       y = "Estimated Marginal Mean\nScore on Stat Quiz",
       linetype = "Self-Rated Math Phobia") +
  theme(legend.background = element_rect(color = "black"),
        legend.position = c(0, 1),
        legend.key.width = unit(2, "cm"),
        legend.justification = c(-0.1, 1.1)) +
  scale_linetype_manual(values = c("solid", "longdash", "dotted"))
```


### APA Write up

> There is evidence both `mathquiz` and `phobia` are associated with `statquiz` and that the relationship is addative (i.e. no interaction).


There is a strong association between math and stats quiz scores, *r* = .51.  Math phobia is associated with lower math, *r* = -.28, and stats quiz scores, *r* = -.36.  When considered together, the combined effects of math phobia and math score account for 31% of the variance in statistical achievement.  

Not surprisingly, while higher self-reported math phobia was associated with lower statistics scores, *b* = -0.162, **p* = .018, 95% *CI* = [-0.29, -0.03]$, higher math quiz scores were associated with higher stats score, *b* = -0.081, *p* < .001, 95% *CI* = [0.05, 0.12].  

There was no evidence that math phobia moderated the relationship between math and quiz performance, *p* = .377. 






