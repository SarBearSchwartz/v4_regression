# Ex: Count - GSS (Hoffman)


Compiled: `r format(Sys.time(), '%B %d, %Y')`

```{r, include=FALSE}
knitr::opts_chunk$set(comment     = "",
                      echo        = TRUE, 
                      warning     = FALSE, 
                      message     = FALSE,
                      fig.align   = "center", # center all figures
                      fig.width   = 6,        # set default figure width to 4 inches
                      fig.height  = 4)        # set default figure height to 3 inches
```




## PREPARATION

### Load Packages

```{r, message=FALSE, error=FALSE, warning=FALSE}
# library(remotes)
# remotes::install_github("sarbearschwartz/apaSupp")  # updated: 4/22/25
# remotes::install_github("sarbearschwartz/texreghelpr")  
# remotes::install_github("ddsjoberg/gtsummary")


library(tidyverse)
library(haven)        
library(naniar)
library(furniture)   # needs table1 for now...
library(apaSupp)
library(performance) 
library(interactions)

library(texreg)
library(texreghelpr)

library(pscl)    # Political Science Computational Laboratory (ZIP)
```



### Load Data





This dataset comes from John Hoffman's textbook: Regression Models for Categorical, Count, and Related Variables: An Applied Approach (2004) [Amazon link, 2014 edition](https://www.amazon.com/Regression-Models-Categorical-Related-Variables/dp/0520289293/ref=sr_1_2?dchild=1&qid=1603172859&refinements=p_27%3ADr.+John+P.+Hoffmann&s=books&sr=1-2&text=Dr.+John+P.+Hoffmann)





```{r}
data_gss <- haven::read_spss("https://raw.githubusercontent.com/CEHS-research/data/master/Hoffmann_datasets/gss.sav") %>% 
  haven::as_factor() %>% 
  haven::zap_label() %>%    # remove SPSS junk
  haven::zap_formats() %>%  # remove SPSS junk
  haven::zap_widths()       # remove SPSS junk
```


```{r}
str(data_gss)
```



```{r}
data_gss %>% 
  dplyr::select(volteer, female, nonwhite, educate, income) %>% 
  tibble::glimpse()
```



## Exploratory Data Analysis


```{r}
apaSupp::spicy_histos(data_gss, var = educate, split = female)
```


```{r}
apaSupp::spicy_histos(data_gss, var = income, split = female)
```



### Entire Sample

```{r}
data_gss %>%
  dplyr::mutate(volteer = factor(volteer)) %>% 
  dplyr::select(volteer) %>% 
  apaSupp::tab_freq()
```


```{r, fig.cap = "Hoffman Figure 6.3"}
data_gss %>% 
  ggplot(aes(volteer)) +
  geom_bar(color = "black", alpha = .4)  +
  theme_bw() +
  labs(x = "Number of Volunteer Activities in the Past Year",
       y = "Frequency") +
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 1))
```

```{block type='rmdlightbulb', echo=TRUE}
**Interpretation:**

The self-reported number of times each person volunteered in the past year is a count (0, 1, 2, ...) that does NOT follow the normal distribution.
```

### By Sex


```{r}
data_gss %>%
  dplyr::mutate(volteer = factor(volteer)) %>% 
  dplyr::select(volteer, female) %>% 
  apaSupp::tab_freq(split = "female")
```


```{r}
data_gss %>% 
  dplyr::group_by(female) %>% 
  furniture::table1(volteer,
                    digits = 4,
                    total = TRUE,
                    test = TRUE)
```

```{r}
data_gss %>% 
  t.test(volteer ~ female,
         data = .,
         var.equal = TRUE) # pooled variance assumes HOV
```


```{block type='rmdlightbulb', echo=TRUE}
**Interpretation:**

Even though there are more women (*n* = 1818, 56%), the woman do report volunteering more over the past year (*M* = 0.35 vs. 0.32 time a year).  This difference is NOT statistically significant when tested with an independent groups t-test, *p* = .365.  The t-test does treat the volunteering variable as if it were normally distributed, which is not the case.
```


```{r}
data_gss %>% 
  dplyr::select(volteer) %>% 
  dplyr::summarise_all(list(mean = mean, 
                            var = var))
```


```{block type='rmdlightbulb', echo=TRUE}
**Interpretation:**

The number of self-reported volunteer activities  is a count, but it is more dispersed that the *Poisson* distribution would expect.  The **over-dispersion** is evident in that the variance (0.78) is much larger than the mean (0.33).  This suggests that the *Negative Binomial* distribution may fit the data better than a *Poisson* distribution.  
```

DV: Count Scale

```{r}
data_gss %>% 
  ggplot(aes(x = female,
             y = volteer)) +
  geom_violin(aes(fill = female), alpha = .4)  +
  stat_summary(fun = mean, geom = "crossbar", color = "red") +
  theme_bw() +
  labs(y = "Number of\nVolunteer Activities in the Past Year",
       x = NULL) +
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2)) +
  scale_fill_manual(values = c("dodgerblue", "coral3"))
```

DV: Log of the Count Scale (plus a tiny amount)

```{r}
data_gss %>% 
  dplyr::mutate(volteer_log = log(volteer + 0.01)) %>% 
  ggplot(aes(x = female,
             y = volteer_log)) +
  geom_violin(aes(fill = female), alpha = .4)  +
  stat_summary(fun = mean, geom = "crossbar", color = "red") +
  theme_bw() +
  labs(y = "Log of 0.01 + Number of\nVolunteer Activities in the Past Year",
       x = NULL) +
  scale_fill_manual(values = c("dodgerblue", "coral3"))
```

## Simple Poisson Reression

Only use the single predictor: `female`

The simple model will give us the "Unadjusted" rates.

### Fit the model

```{r}
glm_possion_1 <- glm(volteer ~ female,
                     data = data_gss,
                     family = poisson(link = "log"))

summary(glm_possion_1)
```


```{block type='rmdlightbulb', echo=TRUE}
**Interpretation:**

The intercept is the predicted log(count) when all the predictors are equal to zero (or the reference category for factors).  Since the only predictor in this model is `female`, the IRR = -1.15 is for males and is statistically significant, *p* < .001.

The parameter estimate for the categorical predictor `female` capture how different the log(count) is for female, compared to males.  This is not statistically significant, p = .165.

Thus far, there is no evidence that males and females volunteer more or less, on average *(marginally)*.
```

> Note: The deviance residuals range as high as 6.47!!!  That is quite high for a z-score.



### Parameter Estimates

```{r}
family(glm_possion_1)
```


#### Link Scale

Coefficients are in terms of the **LOG of** the number of times a person volunteers per year, or log(IRR).

```{r}
glm_possion_1 %>% coef()
```

#### Count Scale

Exponentiation of the coefficients (betas) returns the values to the original scale (number of times a person volunteers per year) and is referred to as the **incident rate ratio (IRR)**.

```{r}
glm_possion_1 %>% coef() %>% exp()
```


```{r}
apaSupp::tab_glm(glm_possion_1)
```





### Predictions

#### Link Scale

> Note: Results are given on the log (not the response) scale

```{r}
glm_possion_1 %>% 
  emmeans::emmeans(~ female)
```


```{block type='rmdlightbulb', echo=TRUE}
**Interpretation:**

Males have a lower log(count) than females, but this difference is not significant due to the good deal of overlap in the confidence intervals.
```

#### Count Scale: 

> Note: These means are on the original scale (number of volunteer activities in the past year).  


These standard errors ARE the so-called "delta-method standard errors" that Stat gives.

```{r}
glm_possion_1 %>% 
  emmeans::emmeans(~ female,
                   type = "response")   
```

These standard errors are **NOT** the so-called "delta-method standard errors" that Stat gives.

```{r}
# Hoffmann Example 6.4 (continued...)
ggeffects::ggemmeans(model = glm_possion_1,
                     terms = c("female")) %>% 
  data.frame()
```


```{r}
0.3467 / 0.3167
```



```{block type='rmdlightbulb', echo=TRUE}
**Interpretation:**

The marginal count/year or *rate* is:
* 0.32 times/year for males
* 0.35 times/year for females

The *incident rate ratio (IRR)* is:
* 9% more times higher, for females compared to males
```




 
## Multiple Poisson Regression

Only using multiple predictors: `female`, `nonwhite`, `educate`, and `income`

The more compled model will give us the "Adjusted" rates


### Fit the model

```{r}
# Hoffmann Example 6.5
glm_possion_2 <- glm(volteer ~ female + nonwhite + educate + income,
                     data = data_gss,
                     family = poisson(link = "log"))

summary(glm_possion_2)
```



### Parameter Estimates
```{r}
apaSupp::tab_glm(glm_possion_2,
                 var_labels = c(female = "Female vs Male",
                                nonwhite = "Nonwhite vs White",
                                educate = "Education",
                                income = "Income"),
                 show_single_row = c("female", "nonwhite"),
                 p_note = "apa23")
```


```{block type='rmdlightbulb', echo=TRUE}
**Interpretation:**

* `female`: Adjusting for the effects of race, education, and income, FEMALES are expected to volunteer about 30% MORE activities per year than males, IRR = 1.29, p < .001.

* `nonwhite`: Adjusting for the effects of sex, education, and income, NON-WHITES are expected to volunteer for about 24% LESS activities per year than males, IRR = 0.76, p = .001.

* `educate`: Each one-year increase in education is associated with an 11% increase in the number of volunteer activities per year, adjusting for the effects of sex, race/ethnicity, and income, IRR = 1.11, p <.001.

* `income`: Each additional $1000 a household makes is associated with a 6% increase in the number of times a person volunteers per year, controlling for sex, race, and education, IRR = 1.06, p < .001.
```


### Predictions


> Note: These means are on the original scale (number of volunteer activities in the past year).  Stata calculates so-called "delta-method standard errors" , but they are not calculated here in R.


```{r}
ggeffects::ggemmeans(model = glm_possion_2,
                     terms = c("female"),
                     condition = c(nonwhite = "white",
                                   educate = 12,
                                   income = 5))
```

```{r}
(0.25 - 0.19) / 0.19
```

```{r}
0.25/0.19
```

```{block type='rmdlightbulb', echo=TRUE}
**Interpretation:**

The expected number of volunteer activities in a year among females is 31.5% higher than among males, for white high school graduates with low income.
```


> Note: `income` = 5 is the 10th percentile of the income distribution.




### Assess Model Fit

```{r}
DescTools::PseudoR2(glm_possion_2)
```


```{r}
DescTools::PseudoR2(glm_possion_2, which = "all") %>% round(3)
```

```{block type='rmdlightbulb', echo=TRUE}
**Interpretation:**

Although these four predictors (sex, race, education, and income) are associated with differences in the number of times a person volunteers annually, together they account for very little of the variance, $R^2_{McF} = .029$, $R^2_{Nag} = .061$.
```


### Residual Diagnostics


```{r, fig.width=6, fig.height=6}
par(mfrow = c(2, 2))
plot(glm_possion_2)
par(mfrow = c(1, 1))
```

```{block type='rmdlightbulb', echo=TRUE}
**Interpretation:**

These residuals do **NOT** look good, especially the Q-Q plot for normality.
```


### Marginal Plot


```{r}
data_gss %>% 
  dplyr::select(educate, income) %>% 
  psych::describe(skew = FALSE)
```


```{r}
data_gss %>% 
  dplyr::select(educate, income) %>% 
  summary()
```


```{r}
interactions::interact_plot(model = glm_possion_2,
                            pred = educate,
                            modx = female,
                            mod2 = nonwhite) +
  theme_bw()
```



```{r, fig.cap="Hoffmann's Figure 6.5"}
ggeffects::ggemmeans(model = glm_possion_2,
                     terms = "educate",
                     condition = c(female = "male",
                                   nonwhite = "white",
                                   incomeN = 11)) %>% 
  data.frame %>% 
  ggplot(aes(x = x,
             y = predicted)) +
  geom_line() +
  labs(x = "Years of Formal Education",
       y = "Predicted Number of Volunteer Activities",
       title = "White Males with median Income (11) ")
```


```{r}
effects::Effect(focal.predictors = c("female", "nonwhite", "educate", "income"),
                mod = glm_possion_2,
                xlevels = list(educate = seq(from = 0, to = 20, by = .1),
                               income  = c(8, 10, 12))) %>% 
  data.frame() %>% 
  dplyr::mutate(income = factor(income) %>% 
                  forcats::fct_recode("Lower Income (8)" = "8",
                                      "Middle Income (10)" = "10",
                                      "Higher Income (12)" = "12")) %>% 
  ggplot(aes(x = educate,
             y = fit)) +
  geom_ribbon(aes(ymin = fit - se,  # bands = +/- 1 SEM
                  ymax = fit + se,
                  fill = female),
              alpha = .2) +
  geom_line(aes(linetype = female,
                color = female),
            size = 1) +
  theme_bw() +
  labs(x = "Education, Years",
       y = "Predicted Mean Number of Volunteer Activities",
       color = NULL,
       fill = NULL,
       linetype = NULL) +
  theme(legend.position = c(0, 1),
        legend.justification = c(-.1, 1.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(2, "cm")) +
  facet_grid(nonwhite ~ income)
```



```{r}
effects::Effect(focal.predictors = c("female", "nonwhite", "educate", "income"),
                mod = glm_possion_2,
                xlevels = list(educate = seq(from = 0, to = 20, by = .1),
                               income  = c(5, 8, 12))) %>% 
  data.frame() %>% 
  dplyr::mutate(income = factor(income)) %>% 
  ggplot(aes(x = educate,
             y = fit)) +
  geom_line(aes(linetype = fct_rev(income),
                color = fct_rev(income)),
            size = 1) +
  theme_bw() +
  labs(x = "Education, Years",
       y = "Predicted Mean Number of Volunteer Activities",
       color = "Income:",
       fill = "Income:",
       linetype = "Income:") +
  theme(legend.position = c(0, 1),
        legend.justification = c(-.1, 1.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(2, "cm")) +
  facet_grid(nonwhite ~ female) +
  scale_linetype_manual(values = c("solid", "longdash", "dotted"))
```



```{r}
effects::Effect(focal.predictors = c("female", "nonwhite", "educate", "income"),
                mod = glm_possion_2,
                xlevels = list(educate = seq(from = 0, to = 20, by = .1),
                               income  = c(8, 10, 12))) %>% 
  data.frame() %>% 
  dplyr::mutate(income = factor(income) %>% 
                  forcats::fct_recode("Lower Income (8)" = "8",
                                      "Middle Income (10)" = "10",
                                      "Higher Income (12)" = "12")) %>% 
  ggplot(aes(x = educate,
             y = fit)) +
  geom_ribbon(aes(ymin = fit - se,  # bands = +/- 1 SEM
                  ymax = fit + se,
                  fill = nonwhite),
              alpha = .2) +
  geom_line(aes(linetype = nonwhite,
                color = nonwhite),
            size = 1) +
  theme_bw() +
  labs(x = "Education, Years",
       y = "Predicted Mean Number of Volunteer Activities",
       color = NULL,
       fill = NULL,
       linetype = NULL) +
  theme(legend.position = c(0, .5),
        legend.justification = c(-.05, 1.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(2, "cm")) +
  facet_grid(female ~ income) +
  scale_color_manual(values = c("darkgreen", "orange")) +
  scale_fill_manual(values = c("darkgreen", "orange"))
```







```{r}
effects::Effect(focal.predictors = c("female", "educate"),
                mod = glm_possion_2,
                xlevels = list(educate = seq(from = 0,
                                             to   = 20,
                                             by = .1),
                               income = 11)) %>%          #Median Income
  data.frame() %>% 
  ggplot(aes(x = educate,
             y = fit,
             group = female)) +
  geom_ribbon(aes(ymin = fit - se,  # bands = +/- 1 SEM
                  ymax = fit + se),
              alpha = .2) +
  geom_line(aes(linetype = female),
            size = 1) +
  theme_bw() +
  labs(x = "Education, Years",
       y = "Predicted Mean Number of Volunteer Activities",
       color = NULL,
       fill = NULL,
       linetype = NULL) +
  theme(legend.position = c(0, 1),
        legend.justification = c(-.1, 1.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(2, "cm")) +
  scale_linetype_manual(values = c("solid", "longdash"))
```


## Negative Binomial Regression

### Multiple Predictors

#### Fit the model

```{r}
glm_negbin_1 <- MASS::glm.nb(volteer ~ female + nonwhite + educate + income,
                             data = data_gss)

summary(glm_negbin_1)
```

> Note: the deviance residuals all have absolute values less than 3-4'ish...better than before


**Theta in R = 1/alpha in Stata**

```{r, results='asis'}
# Hoffmann Example 6.5
texreg::knitreg(list(glm_possion_2, 
                       texreghelpr::extract_glm_exp(glm_possion_2,
                                                    include.aic = FALSE,
                                                    include.bic = FALSE,
                                                    include.loglik = FALSE,
                                                    include.deviance = FALSE,
                                                    include.nobs = FALSE)),
                  custom.model.names = c("b (SE)", "IRR [95% CI]"),
                  custom.coef.map = list("(Intercept)" ="Intercept",
                                         femalefemale = "Female vs. Male",
                                         "nonwhitenon-white" = "Non-white vs. White",
                                         educate = "Education, years",
                                         income = "Income, 1000's"),
                  caption = "GLM: Multiple Possion Regression",
                  single.row = TRUE,
                  digits = 3)
```


#### Predictions


> Note: These means are on the original scale (number of volunteer activities in the past year).  These standard errors are called "delta-method standard errors"

```{r}
effects::Effect(focal.predictors = c("female"),
                mod = glm_negbin_1,
                xlevels = list(nonwhite = "non-white",
                               educate = 5,
                               income = 12)) %>% 
  data.frame()
```

```{r}
ggeffects::ggemmeans(model = glm_negbin_1,
                     terms = c("female"),
                     condition = c(nonwhite = "white",
                                   educate = 12,
                                   income = 5))
```


Compare to the Poisson:

```{r}
ggeffects::ggemmeans(model = glm_possion_2,
                     terms = c("female"),
                     condition = c(nonwhite = "white",
                                   educate = 12,
                                   income = 5))
```

Note: The predictions are very similar for Poisson and Negative Binomial...therefor the overdisperssion does not affect the sex difference much, but it may affect other things... 




#### Parameter Estimates

Coefficients are in terms of the **LOG of** the number of times a person volunteers per year.

```{r}
glm_negbin_1 %>% coef()
```

Exponentiating the coefficients (betas) returns the values to the original scale (number of times a person volunteers per year) and is called the **incident rate ratio IRR**.

```{r}
glm_negbin_1 %>% coef() %>% exp()
```



```{r, results='asis'}
texreg::knitreg(list(glm_negbin_1, 
                       texreghelpr::extract_glm_exp(glm_negbin_1,
                                                    include.aic = FALSE,
                                                    include.bic = FALSE,
                                                    include.loglik = FALSE,
                                                    include.deviance = FALSE,
                                                    include.nobs = FALSE)),
                  custom.model.names = c("b (SE)", "IRR [95% CI]"),
                  custom.coef.map = list("(Intercept)" ="Intercept",
                                         femalefemale = "Female vs. Male",
                                         "nonwhitenon-white" = "Non-white vs. White",
                                         educate = "Education, Years",
                                         income = "Income"),
                  caption = "GLM: Negitive Binomial Regression",
                  single.row = TRUE,
                  digits = 3)
```



#### Residual Diagnostics


```{r}
par(mfrow = c(2, 2))
plot(glm_negbin_1)
par(mfrow = c(1, 1))
```

These still don't look very good :(


#### Compare models




```{r}
performance::compare_performance(glm_possion_2, glm_negbin_1, rank = TRUE)
```




## Zero Inflated Poisson


### Fit the model

```{r}
glm_zip_1 <- pscl::zeroinfl(volteer ~ female + nonwhite + educate + income | educate,
                               data = data_gss)

summary(glm_zip_1)
```



```{r}
glm_zip_1 %>% coef() %>% exp()
```



> Compares two models fit to the same data that do not nest via Vuong's non-nested test.

```{r}
pscl::vuong(glm_zip_1, glm_possion_2)
```




## Zero Inflated Negative Binomial


### Fit the model

```{r}
glm_zinb_1 <- pscl::zeroinfl(volteer ~ female + nonwhite + educate + income | educate,
                               data = data_gss,
                             dist = "negbin")

summary(glm_zinb_1)
```



```{r}
glm_zinb_1 %>% coef() %>% exp()
```




## Compare Models


```{r}
pscl::vuong(glm_zinb_1, glm_negbin_1)
```


```{r}
pscl::vuong(glm_zip_1, glm_zinb_1)
```

 
```{r}
performance::compare_performance(glm_possion_2, glm_zip_1, 
                                 glm_negbin_1, glm_zinb_1) %>% 
  data.frame() %>% 
  dplyr::select(Name, AICc, BIC, RMSE,
                R2, R2_adjusted, R2_Nagelkerke) %>% 
  dplyr::mutate(across(starts_with("R2"), ~apaSupp::p_num(.x, stars = FALSE))) %>% 
  flextable::flextable() %>% 
  apaSupp::theme_apa(caption = "Compare Model Fits")
```
 
 
 
 The 'best' model is the zero-inflated negative binomial
 
 ## Final

 
```{r, fig.cap="Worst Model: Poisson"}
glm_possion_2 %>% 
  emmeans::emmeans(~ female + educate + income,
                   at = list(educate = seq(from = 8,
                                             to = 18,
                                             by = .1),
                               income  = c(8, 10, 12)),
                   type = "response") %>% 
  data.frame() %>% 
  dplyr::mutate(income = factor(income) %>% 
                  forcats::fct_recode("Lower Income (8)" = "8",
                                      "Middle Income (10)" = "10",
                                      "Higher Income (12)" = "12")) %>% 
  dplyr::mutate(income = forcats::fct_rev(income)) %>% 
  dplyr::mutate(female = forcats::fct_rev(female)) %>% 
  ggplot(aes(x = educate,
             y = rate)) +
  geom_vline(xintercept = 12) +
  geom_line(aes(linetype = income,
                color = female),
            size = 1) +
  theme_bw() +
  labs(x = "Education, Years",
       y = "Predicted Rate\nVolunteer Activities in the Prior Year",
       color = NULL,
       fill = NULL,
       linetype = NULL) +
  theme(legend.position = c(0, 1),
        legend.justification = c(-.1, 1.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(2, "cm")) +
  scale_linetype_manual(values = c("solid", "longdash", "dotted")) +
  scale_x_continuous(breaks = seq(from = 8, to = 20, by = 2))
```
 
```{r, fig.cap="Best Model: Zero Inflated Negative Binomial"}
glm_zinb_1 %>% 
  emmeans::emmeans(~ female + educate + income,
                   at = list(educate = seq(from = 8,
                                             to = 18,
                                             by = .1),
                               income  = c(8, 10, 12)),
                   type = "response") %>% 
  data.frame() %>% 
  dplyr::mutate(income = factor(income) %>% 
                  forcats::fct_recode("Lower Income (8)" = "8",
                                      "Middle Income (10)" = "10",
                                      "Higher Income (12)" = "12")) %>% 
  dplyr::mutate(income = forcats::fct_rev(income)) %>% 
  dplyr::mutate(female = forcats::fct_rev(female)) %>% 
  ggplot(aes(x = educate,
             y = emmean)) +
  geom_vline(xintercept = 12) +
  geom_line(aes(linetype = income,
                color = female),
            size = 1) +
  theme_bw() +
  labs(x = "Education, Years",
       y = "Predicted Rate\nVolunteer Activities in the Prior Year",
       color = NULL,
       fill = NULL,
       linetype = NULL) +
  theme(legend.position = c(0, 1),
        legend.justification = c(-.1, 1.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(2, "cm")) +
  scale_linetype_manual(values = c("solid", "longdash", "dotted")) +
  scale_x_continuous(breaks = seq(from = 8, to = 20, by = 2))
```
