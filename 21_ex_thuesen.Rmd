# Ex: Ventricular Shortening Velocity

![](images/common/ISwR_thuesen.PNG)



```{r, comment=FALSE, message=FALSE}
# install.packages("remotes")
# remotes::install_github("sarbearschwartz/apaSupp")
# remotes::install_github("ddsjoberg/gtsummary")

library(magrittr)       
library(tidyverse)   
library(broom)     
library(naniar)
library(corrplot)   
library(GGally)
library(gtsummary)
library(apaSupp)
library(performance)
library(interactions)
library(effects)
library(emmeans)
library(car)
library(ggResidpanel)
library(modelsummary)
library(ppcor)
library(jtools)
library(olsrr)
library(DescTools)
library(effectsize)
library(ggpubr)

library(ISwR)            # Introduction to Statistics with R (datasets)
```

## PURPOSE

### Research Question

> Is there a relationship between fasting blood glucose and shortening of ventricular velocity among type 1 diabetic patiences?  If so, what is the nature of the association?


### Data Description

This dataset is included in the `ISwR` package [@R-ISwR], which was a companion to the texbook "Introductory Statistics with R, 2nd ed." [@dalgaard2008], although it was first published by @altman1991 in Table 11.6. 


> The `thuesen` data frame has 24 rows and 2 columns. It contains ventricular shortening velocity and blood glucose for type 1 diabetic patients.

* `blood.glucose` a numeric vector, fasting blood glucose (mmol/l).
* `short.velocity` a numeric vector, mean circumferential shortening velocity (%/s).


```{r}
data(thuesen, package = "ISwR")
```


```{r}
tibble::glimpse(thuesen)  # view the class and 1st few values of each variable
```


## EXPLORATORY DATA ANALYSIS

```{block type='rmdimportant', echo=TRUE}
Before embarking on any inferencial anlaysis or modeling, always get familiar with your variables one at a time *(univariate)*, as well as pairwise *(bivariate)*.
```

### Univariate Statistics

Summary Statistics for all three variables of interest


Center: mean and median
Spread: standard deviation, range (max - min), interquartile range (Q3 - Q1)

```{r}
thuesen %>% 
  dplyr::select("Fasting Blood Glucose" = blood.glucose, 
                "Circumferential Shortening Velocity" = short.velocity) %>% 
  apaSupp::tab_desc(caption = "Description of Diabetic Participants")
```



### Univariate Visualizations

```{r}
thuesen %>% 
  apaSupp::spicy_histos(var = blood.glucose)
```


```{r}
thuesen %>% 
  apaSupp::spicy_histos(var = short.velocity)
```





### Bivariate Statistics 

(Unadjusted Pearson's correlation)

The `cor()` fucntion in base $R$ doesn't like `NA` or missing values

```{r}
thuesen %>% cor()           
```

```{block type='rmdlightbulb', echo=TRUE}
You may specify how to handle cases that are missing on at least one of the variables of interest:

* `use = "everything"` `NA`s will propagate conceptually, i.e., a resulting value will be `NA` whenever one of its contributing observations is `NA` **<-- DEFAULT**
* `use = "all.obs"` the presence of missing observations will produce an error
* `use = "complete.obs"` missing values are handled by casewise deletion (and if there are no complete cases, that gives an error). 
* `use = "na.or.complete"` is the same as above unless there are no complete cases, that gives `NA` 
* `use = "pairwise.complete.obs"` the correlation between each pair of variables is computed using all complete pairs of observations on those variables. This can result in covariance matrices which are not positive semi-definite, as well as `NA` entries if there are no complete pairs for that pair of variables. 
```

Commonly, we want  **listwise deletion**:

```{r}
thuesen %>% cor(use = "complete.obs")   # list-wise deletion
```



It is also handy to specify the  number of decimal places desired, but adding a rounding step:

```{r}
thuesen %>% 
  cor(use = "complete.obs") %>%   
  round(2)                       # number od decimal places
```


If you desire a correlation single value of a single PAIR of variables, instead of a matrix, then you must use a **`magrittr` exposition pipe (`%$%`)** 

```{r}
thuesen %$%                            # notice the special kind of pipe
  cor(blood.glucose, short.velocity,   # specify exactly TWO variables            
      use = "complete.obs")
```

In addition to the `cor()` funciton, the base $R$ `stats` package also includes the `cor.test()` function to test if the correlation is zero ($H_0: R = 0$)

This TESTS if the cor == 0
```{r}
thuesen %$%                                 # notice the special kind of pipe
  cor.test(blood.glucose, short.velocity,   # specify exactly TWO variables            
           use="complete.obs")
```


The default correltaion type for `cor()`is **Pearson's $R$**, which assesses linear relationships.  **Spearman's correlation** assesses monotonic relationships.

```{r}
thuesen %$%                            # notice the special kind of pipe
  cor(blood.glucose, short.velocity,   # specify exactly TWO variables  
      use    = 'complete',
      method = 'spearman')       # spearman's (rho) 
```




### Bivariate Visualization



```{r}
ggplot(thuesen, 
       aes(x = blood.glucose,        # x-axis variable
           y = short.velocity)) +    # y-axis variable
  geom_point() +                     # place a point for each observation
  geom_smooth(method = "lm",
              formula = y ~ x) +
  ggpubr::stat_regline_equation(label.x = 5,
                                label.y = 1.85,
                                size = 6) +
  theme_bw() +
  labs(x = "Blood Glucose, mmol/l",
       y = "Mean Circumferential Shortening Velocity, %/s")
```






## REGRESSION ANALYSIS

* `short.velocity` dependent variable or outcome ($Y$)
* `blood.glucose` independent variable or predictor ($X$)


### Fit A Simple Linear Model


$$
Y = \beta_0 + \beta_1 \times X
$$


```{block type='rmdlightbulb', echo=TRUE}
The `lm()` function must be supplied with at least two options:

* a formula:  `Y ~ X`
* a dataset: `data = XXXXXXX`

When a model is fit and directly saved as a named object via the assignment opperator (`<-`), no output is produced.
```





```{r}
fit_vel_glu <- lm(short.velocity ~ blood.glucose, 
                  data = thuesen)
```


Running the name of the fit object yields very little output:

```{r}
fit_vel_glu
```


Appling the `summary()` function produced a good deal more output:

```{r}
summary(fit_vel_glu)
```

You may request specific pieces of the output:

* Coefficients or beta estimates:

```{r}
coef(fit_vel_glu)
```

* 95% confidence intervals for the coefficients or beta estimates:

```{r}
confint(fit_vel_glu)
```

* The F-test for overall modle fit vs. a $null$ or empty model having only an intercept and no predictors.

```{r}
anova(fit_vel_glu)
```

* Various other model fit indicies:


```{r}
logLik(fit_vel_glu)     
AIC(fit_vel_glu)
BIC(fit_vel_glu)
```


### Checking Assumptions via Residual Diagnostics

```{block type='rmdimportant', echo=TRUE}
Before reporting a model, ALWAYS make sure to check the residules to ensure that the model assumptions are not violated.
```


```{r}
plot(fit_vel_glu, which = 1)
```

```{r}
plot(fit_vel_glu, which = 2)
```

```{r}
plot(fit_vel_glu, which = 5)
```

```{r}
plot(fit_vel_glu, which = 6)
```



```{r}
performance::check_residuals(fit_vel_glu)
```

```{r}
ggResidpanel::resid_panel(fit_vel_glu)
```


Viewing potentially influential or outlier points based on plots above:

```{r}
thuesen %>% 
  dplyr::mutate(id = row_number()) %>% 
  dplyr::filter(id == c(13, 20, 24))
```



Here is a fancy way to visulaize 'potential problem cases' with `ggplot2`:

```{r}
thuesen %>% 
  dplyr::filter(complete.cases(.)) %>%                # keep only complete cases
  ggplot() +                                          # name the FULL dataset 
  aes(x = blood.glucose,                              # x-axis variable name
      y = short.velocity) +                           # y-axis variable name
  geom_point() +                                      # do a scatterplot
  stat_smooth(method = "lm") +                        # smooth: linear model
  theme_bw()  +                                       # black-and-while theme
  geom_point(data = thuesen %>%                       # override the dataset from above
               filter(row_number() == c(13, 20, 24)), # with a reduced subset of cases
             size = 4,                                # make the points bigger in size 
             color = "red")                           # give the points a different color
```




### Visualize Relationships



```{block type='rmdimportant', echo=TRUE}
When a model only contains main effects, a plot is not important for interpretation, but can help understand the relationship between multiple predictors.
```

```{block type='rmdlightbulb', echo=TRUE}
The `Effect()` function from the `effects` package chooses '5 or 6 nice values' for your continuous independent variable ($X$) based on the range of values found in the dataset on which the model was fit and plugs them into the regression equation $Y = \beta_0 + \beta_1 \times X$ to compute the predicted *mean* value of the outcome ($Y$) [@R-effects].
```


```{r}
effects::Effect(focal.predictors = c("blood.glucose"),  # IV variable name
                mod = fit_vel_glu)                      # fitted model name
```

You may override the 'nice values' using the `xlevels = list(var_name = c(#, #, ...#)` option.

```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu,
                xlevels = list(blood.glucose = c(5, 10, 15, 20))) 
```

Adding a piped data frame step (` %>% data.frame()`) will arrange the predicted $Y$ values into a column called `fit`.  This tidy data format is ready for plotting.

```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu) %>% 
  data.frame() 
```



```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu,
                xlevels = list(blood.glucose = c(5, 12, 20))) %>% 
  data.frame() %>% 
  ggplot() +
  aes(x = blood.glucose,           # x-axis variable
      y = fit) +                   # y-axis variable
  geom_ribbon(aes(ymin = lower,    # bottom edge of the ribbon
                  ymax = upper),   # top edge of the ribbon
              alpha = .5) +        # ribbon transparency level
  geom_line() +
  theme_bw()
```




Notice that although the regression line is smooth, the ribbon is choppy.  This is because we are basing it on only THREE values of $X$.


```{r}
c(5, 12, 20)
```

Use the `seq()` function in base $R$ to request many values of $X$

```{r}
seq(from = 5, to = 20, by = 5)
```

```{r}
seq(from = 5, to = 20, by = 2)
```

```{r}
seq(from = 5, to = 20, by = 1)
```



```{r}
seq(from = 5, to = 20, by = .5)
```




```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu,
                xlevels = list(blood.glucose = seq(from = 5, to = 20, by = .5))) %>% 
  data.frame() %>% 
  ggplot() +
  aes(x = blood.glucose,           # x-axis variable
      y = fit) +                   # y-axis variable
  geom_ribbon(aes(ymin = lower,    # bottom edge of the ribbon
                  ymax = upper),   # top edge of the ribbon
              alpha = .5) +        # ribbon transparency level
  geom_line() +
  theme_bw()
```

Now that we are basing our ribbon on MANY more points of $X$, the ribbon is much smoother.


For publication, you would of course want to clean up the plot a bit more:



```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu,
                xlevels = list(blood.glucose = seq(from = 5, to = 20, by = .5))) %>% 
  data.frame() %>% 
  ggplot() +
  aes(x = blood.glucose,           # x-axis variable
      y = fit) +                   # y-axis variable
  geom_ribbon(aes(ymin = lower,    # bottom edge of the ribbon
                  ymax = upper),   # top edge of the ribbon
              alpha = .3) +        # ribbon transparency level
  geom_line() +
  theme_bw()
```



The above plot has a ribbon that represents a 95% confidence interval (`lower` to`upper`) for the MEAN (`fit`) outcome.  Sometimes we would rather display a ribbon for only the MEAN (`fit`) plus-or-minus ONE STANDARD ERROR (`se`) for the mean.  You would do that by changing the variables that define the min and max edges of the ribbon (notice the range of the y-axis has changed):

```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu,
                xlevels = list(blood.glucose = seq(from = 5, to = 20, by = .5))) %>% 
  data.frame() %>% 
  ggplot() +
  aes(x = blood.glucose,           
      y = fit) +                   
  geom_ribbon(aes(ymin = fit - se,    # bottom edge of the ribbon
                  ymax = fit + se),   # top edge of the ribbon
              alpha = .3) +        
  geom_line() +
  theme_bw()   
```



Of course, you could do both ribbons together:


```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu,
                xlevels = list(blood.glucose = seq(from = 5, to = 20, by = .5))) %>% 
  data.frame() %>% 
  ggplot() +
  aes(x = blood.glucose,           
      y = fit) +                  
  geom_ribbon(aes(ymin = lower,    # bottom edge of the ribbon = lower of the 95% CI
                  ymax = upper),   # top edge of the ribbon = upper of the 95% CI
              alpha = .3) +        
  geom_ribbon(aes(ymin = fit - se,    # bottom edge of the ribbon = mean - SE
                  ymax = fit + se),   # top edge of the ribbon = Mean + SE
              alpha = .3) +        
  geom_line() +
  theme_bw() 
```






## CONCLUSION


### Table

You may also present the output in a table using two different packages:

```{r}
apaSupp::tab_lm(fit_vel_glu,
                var_labels = c("blood.glucose" = "Blood Glucose"),
                caption = "Parameter Estimates for Mean Circumferential Shortening Velocity Regressed on Fasting Blood Glucose",
                general_note = "Units are perceont per second for mean circumferential shortening velocity and mmol per liter for fasting blood glucose.")
```




### Plot


```{r}
effects::Effect(focal.predictors = c("blood.glucose"),
                mod = fit_vel_glu,
                xlevels = list(blood.glucose = seq(from = 5, to = 20, by = .5))) %>% 
  data.frame() %>% 
  ggplot() +
  aes(x = blood.glucose,           
      y = fit) +                   
  geom_ribbon(aes(ymin = fit - se,    # bottom edge of the ribbon
                  ymax = fit + se),   # top edge of the ribbon
              alpha = .3) +        
  geom_line() +
  theme_bw() +
  labs(x = "Fasting Blood Glucose (mmol/l)",
       y = "EStimated Marginal Mean\nMean Circumferential Shortening Velocity (%/s)")   
```



### APA Write up

> There is evidence `blood.glucose` is associated with `short.velocity`.

In this sample of Type 1 Diabetic patient (*n* = 24), there is a moderate positive correlation between fasting blood glucose (*M* = 10.30 mmol/l, *SD* = 4.34) and shortening of ventricular velocity (*M* = 1.33 %/s, *SD* = 0.23), *r* = .417, *p* = .048. An increase of 1 mmol/l fasting blood glucose is associated with a .02 %/s increase in ventricular velocity shortening, *b* = 0.02, *SE* = 0.01, *p* = .048, $R^2$ = .
