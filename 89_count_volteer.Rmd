# Count Outcome Regression - Ex: 

```{r, include=FALSE}
knitr::opts_chunk$set(comment     = "",
                      echo        = TRUE, 
                      warning     = FALSE, 
                      message     = FALSE,
                      fig.align   = "center", # center all figures
                      fig.width   = 6,        # set default figure width to 4 inches
                      fig.height  = 4)        # set default figure height to 3 inches
```

```{r, message=FALSE, error=FALSE}
library(tidyverse)
library(haven)        # read in SPSS dataset
library(furniture)    # nice table1() descriptives
library(stargazer)    # display nice tables: summary & regression
library(texreg)       # Convert Regression Output to LaTeX or HTML Tables
library(psych)        # contains some useful functions, like headTail
library(car)          # Companion to Applied Regression
library(sjPlot)       # Quick plots and tables for models
library(glue)         # Interpreted String Literals 

library(DescTools)    # Tools for Descriptive Statistics
library(texreghelpr)  # Helper Functions for generalized models

library(pscl)         # Political Science Computational Laboratory (ZIP)
```

## Background


This dataset comes from John Hoffman's textbook: Regression Models for Categorical, Count, and Related Variables: An Applied Approach (2004) [Amazon link, 2014 edition](https://www.amazon.com/Regression-Models-Categorical-Related-Variables/dp/0520289293/ref=sr_1_2?dchild=1&qid=1603172859&refinements=p_27%3ADr.+John+P.+Hoffmann&s=books&sr=1-2&text=Dr.+John+P.+Hoffmann)



### Raw Dataset

```{r}
data_gss <- haven::read_spss("https://raw.githubusercontent.com/CEHS-research/data/master/Hoffmann_datasets/gss.sav") %>% 
  haven::as_factor()

data_gss %>% 
  dplyr::select(volteer, female, nonwhite, educate, income) %>% 
  head()
```



## Exploratory Data Analysis

### Entire Sample

```{r}
data_gss %>% 
  furniture::tableF(volteer)
```


```{r, fig.cap = "Hoffman Figure 6.3"}
data_gss %>% 
  ggplot(aes(volteer)) +
  geom_bar(color = "black", alpha = .4)  +
  theme_bw() +
  labs(x = "Number of Volunteer Activities in the Past Year",
       y = "Frequency") +
  scale_x_continuous(breaks = seq(from = 0, to = 10, by = 1))
```
**Interpretation:**

The self-reported number of times each person volunteered in the past year is a count (0, 1, 2, ...) that does NOT follow the normal distribution.


### By Sex


```{r}
data_gss %>% 
  dplyr::group_by(female) %>% 
  furniture::table1(factor(volteer),
                    digits = 4,
                    total = TRUE)
```


```{r}
data_gss %>% 
  dplyr::group_by(female) %>% 
  furniture::table1(volteer,
                    digits = 4,
                    total = TRUE,
                    test = TRUE)
```

```{r}
data_gss %>% 
  t.test(volteer ~ female,
         data = .,
         var.equal = TRUE) # pooled variance assumes HOV
```

**Interpretation:**

Even though there are more women (n = 1818, 56% of N = 2903), the woman do report volunteering more over the past year (M = 0.35 vs. 0.32 time a year).  This difference is NOT statistically significant when tested with an independent groups t-test, p = .365.  The t-test does treat the volunteering variable as if it were normally distributed, which is not the case.



```{r}
data_gss %>% 
  dplyr::select(volteer) %>% 
  dplyr::summarise_all(funs(mean, var))
```

**Interpretation:**

The number of self-reported volunteer activities  is a count, but it is more dispersed that the *Poisson* distribution would expect.  The **over-dispersion** is evident in that the variance (0.78) is much larger than the mean (0.33).  This suggests that the *Negative Binomial* distribution may fit the data better than a *Poisson* distribution.  


DV: Count Scale

```{r}
data_gss %>% 
  ggplot(aes(x = female,
             y = volteer)) +
  geom_violin(aes(fill = female), alpha = .4)  +
  stat_summary(fun = mean, geom = "crossbar", color = "red") +
  theme_bw() +
  labs(y = "Number of\nVolunteer Activities in the Past Year",
       x = NULL) +
  scale_y_continuous(breaks = seq(from = 0, to = 10, by = 2)) +
  scale_fill_manual(values = c("dodgerblue", "coral3"))
```

DV: Log of the Count Scale (plus a tiny amount)

```{r}
data_gss %>% 
  dplyr::mutate(volteer_log = log(volteer + 0.01)) %>% 
  ggplot(aes(x = female,
             y = volteer_log)) +
  geom_violin(aes(fill = female), alpha = .4)  +
  stat_summary(fun = mean, geom = "crossbar", color = "red") +
  theme_bw() +
  labs(y = "Log of 0.01 + Number of\nVolunteer Activities in the Past Year",
       x = NULL) +
  scale_fill_manual(values = c("dodgerblue", "coral3"))
```

## Simple Poisson Reression

Only use the single predictor: `female`

The simple model will give us the "Unadjusted" rates.

### Fit the model

```{r}
glm_possion_1 <- glm(volteer ~ female,
                     data = data_gss,
                     family = poisson(link = "log"))

summary(glm_possion_1)
```

**Interpretation:**

The intercept is the predicted log(count) when all the predictors are equal to zero (or the reference category for factors).  Since the only predictor in this model is `female`, the IRR = -1.15 is for males and is statistically significant, p < .001.

The parameter estimate for the categorical predictor `female` capture how different the log(count) is for female, compared to males.  This is not statistically significant, p = .165.

Thus far, there is no evidence that males and females volunteer more or less, on average *(marginally)*.


> Note: The deviance residuals range as high as 6.47!!!  That is quite high for a z-score.



### Parameter Estimates


#### Link Scale

Coefficients are in terms of the **LOG of** the number of times a person volunteers per year, or log(IRR).

```{r}
glm_possion_1 %>% coef()
```

#### Count Scale

Exponentiation of the coefficients (betas) returns the values to the original scale (number of times a person volunteers per year) and is referred to as the **incident rate ratio (IRR)**.

```{r}
glm_possion_1 %>% coef() %>% exp()
```


```{r, results='asis'}
# Hoffmann Example 6.4
texreg::knitreg(list(glm_possion_1, 
                     texreghelpr::extract_glm_exp(glm_possion_1,
                                                  include.aic = FALSE,
                                                  include.bic = FALSE,
                                                  include.loglik = FALSE,
                                                  include.deviance = FALSE,
                                                  include.nobs = FALSE)),
                custom.model.names = c("b (SE)", "IRR [95 CI]"),
                custom.coef.map = list("(Intercept)" ="Intercept",
                                       femalefemale = "Female vs. Male"),
                caption = "GLM: Simple Possion Regression",
                single.row = TRUE,
                digits = 3,
                ci.test = 1)
```




### Predictions

#### Link Scale

> Note: Results are given on the log (not the response) scale

```{r}
glm_possion_1 %>% 
  emmeans::emmeans(~ female)
```

**Interpretation:**

Males have a lower log(count) than females, but this difference is not significant due to the good deal of overlap in the confidence intervals.


#### Count Scale: 

> Note: These means are on the original scale (number of volunteer activities in the past year).  


These standard errors ARE the so-called "delta-method standard errors" that Stat gives.

```{r}
glm_possion_1 %>% 
  emmeans::emmeans(~ female,
                   trans = "unlink")   
```

These standard errors are NOT the so-called "delta-method standard errors" that Stat gives.

```{r}
# Hoffmann Example 6.4 (continued...)
ggeffects::ggemmeans(model = glm_possion_1,
                     terms = c("female")) %>% 
  data.frame()
```
```{r}
0.3467 / 0.3167
```


**Interpretation:**

The marginal count or *rate* is:
* 0.32 times/year for males
* 0.35 times/year for females

The *incident rate ratio (IRR)* is:
* 9% more times higher, for females compared to males





 
## Multiple Poisson Regression

Only using multiple predictors: `female`, `nonwhite`, `educate`, and `income`

The more compled model will give us the "Adjusted" rates


### Fit the model

```{r}
# Hoffmann Example 6.5
glm_possion_2 <- glm(volteer ~ female + nonwhite + educate + income,
                     data = data_gss,
                     family = poisson(link = "log"))

summary(glm_possion_2)
```



### Parameter Estimates


```{r, results='asis'}
texreg::knitreg(list(glm_possion_2, 
                     texreghelpr::extract_glm_exp(glm_possion_2,
                                                  include.aic = FALSE,
                                                  include.bic = FALSE,
                                                  include.loglik = FALSE,
                                                  include.deviance = FALSE,
                                                  include.nobs = FALSE)),
                custom.model.names = c("b (SE)", "IRR [95 CI]"),
                custom.coef.map = list("(Intercept)" ="Intercept",
                                       femalefemale = "Female vs. Male",
                                       "nonwhitenon-white" = "Non-white vs. White",
                                       educate = "Education, Years",
                                       income = "Income"),
                caption = "GLM: Multiple Possion Regression",
                single.row = TRUE,
                ci.test = 1,
                digits = 3)
```


**Interpretation:**

* `female`: Adjusting for the effects of race, education, and income, FEMALES are expected to volunteer about 30% MORE activities per year than males, exp(b) = 1.29, p < .001.

* `nonwhite`: Adjusting for the effects of sex, education, and income, NON-WHITES are expected to volunteer for about 24% LESS activities per year than males, exp(b) = 0.76, p = .001.

* `educate`: Each one-year increase in education is associated with an 11% increase in the number of volunteer activities per year, adjusting for the effects of sex, race/ethnicity, and income, exp(b) = 1.11, p <.001.

* `income`: Each additional $1000 a household makes is associated with a 6% increase in the number of times a person volunteers per year, controlling for sex, race, and education, exp(b) = 1.06, p < .001.



### Predictions


> Note: These means are on the original scale (number of volunteer activities in the past year).  Stata calculates so-called "delta-method standard errors" , but they are not calculated here in R.


```{r}
ggeffects::ggemmeans(model = glm_possion_2,
                     terms = c("female"),
                     condition = c(nonwhite = "white",
                                   educate = 12,
                                   income = 5))
```

```{r}
(0.25 - 0.19) / 0.19
```

```{r}
0.25/0.19
```


**Interpretation:**

The expected number of volunteer activities in a year among females is 31.5% higher than among males, for white high school graduates with low income.



> Note: `income` = 5 is the 10th percentile of the income distribution.




### Assess Model Fit

```{r}
DescTools::PseudoR2(glm_possion_2)
```


```{r}
DescTools::PseudoR2(glm_possion_2, which = "all") %>% round(3)
```

**Interpretation:**

Although these four predictors (sex, race, education, and income) are associated with differences in the number of times a person volunteers annually, together they account for very littel of the variance, $R^2_{McF} = .029$, $R^2_{Nag} = .061$.



### Residual Diagnostics


```{r, fig.width=6, fig.height=6}
par(mfrow = c(2, 2))
plot(glm_possion_2)
par(mfrow = c(1, 1))
```

**Interpretation:**

These residuals do **NOT** look good, especially the Q-Q plot for normality.



### Marginal Plot


```{r}
data_gss %>% 
  dplyr::select(educate, income) %>% 
  psych::describe(skew = FALSE)
```


```{r}
data_gss %>% 
  dplyr::select(educate, income) %>% 
  summary()
```

```{r, fig.cap="Hoffmann's Figure 6.5"}
ggeffects::ggemmeans(model = glm_possion_2,
                     terms = "educate",
                     condition = c(female = "male",
                                   nonwhite = "white",
                                   incomeN = 11)) %>% 
  data.frame %>% 
  ggplot(aes(x = x,
             y = predicted)) +
  geom_line() +
  labs(x = "Years of Formal Education",
       y = "Predicted Number of Volunteer Activities",
       title = "White Males with median Income (11) ")
```


```{r}
effects::Effect(focal.predictors = c("female", "nonwhite", "educate", "income"),
                mod = glm_possion_2,
                xlevels = list(educate = seq(from = 0, to = 20, by = .1),
                               income  = c(8, 10, 12))) %>% 
  data.frame() %>% 
  dplyr::mutate(income = factor(income) %>% 
                  forcats::fct_recode("Lower Income (8)" = "8",
                                      "Middle Income (10)" = "10",
                                      "Higher Income (12)" = "12")) %>% 
  ggplot(aes(x = educate,
             y = fit)) +
  geom_ribbon(aes(ymin = fit - se,  # bands = +/- 1 SEM
                  ymax = fit + se,
                  fill = female),
              alpha = .2) +
  geom_line(aes(linetype = female,
                color = female),
            size = 1) +
  theme_bw() +
  labs(x = "Education, Years",
       y = "Predicted Mean Number of Volunteer Activities",
       color = NULL,
       fill = NULL,
       linetype = NULL) +
  theme(legend.position = c(0, 1),
        legend.justification = c(-.1, 1.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(2, "cm")) +
  facet_grid(nonwhite ~ income)
```



```{r}
effects::Effect(focal.predictors = c("female", "nonwhite", "educate", "income"),
                mod = glm_possion_2,
                xlevels = list(educate = seq(from = 0, to = 20, by = .1),
                               income  = c(5, 8, 12))) %>% 
  data.frame() %>% 
  dplyr::mutate(income = factor(income)) %>% 
  ggplot(aes(x = educate,
             y = fit)) +
  geom_line(aes(linetype = fct_rev(income),
                color = fct_rev(income)),
            size = 1) +
  theme_bw() +
  labs(x = "Education, Years",
       y = "Predicted Mean Number of Volunteer Activities",
       color = "Income:",
       fill = "Income:",
       linetype = "Income:") +
  theme(legend.position = c(0, 1),
        legend.justification = c(-.1, 1.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(2, "cm")) +
  facet_grid(nonwhite ~ female) +
  scale_linetype_manual(values = c("solid", "longdash", "dotted"))
```



```{r}
effects::Effect(focal.predictors = c("female", "nonwhite", "educate", "income"),
                mod = glm_possion_2,
                xlevels = list(educate = seq(from = 0, to = 20, by = .1),
                               income  = c(8, 10, 12))) %>% 
  data.frame() %>% 
  dplyr::mutate(income = factor(income) %>% 
                  forcats::fct_recode("Lower Income (8)" = "8",
                                      "Middle Income (10)" = "10",
                                      "Higher Income (12)" = "12")) %>% 
  ggplot(aes(x = educate,
             y = fit)) +
  geom_ribbon(aes(ymin = fit - se,  # bands = +/- 1 SEM
                  ymax = fit + se,
                  fill = nonwhite),
              alpha = .2) +
  geom_line(aes(linetype = nonwhite,
                color = nonwhite),
            size = 1) +
  theme_bw() +
  labs(x = "Education, Years",
       y = "Predicted Mean Number of Volunteer Activities",
       color = NULL,
       fill = NULL,
       linetype = NULL) +
  theme(legend.position = c(0, .5),
        legend.justification = c(-.05, 1.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(2, "cm")) +
  facet_grid(female ~ income) +
  scale_color_manual(values = c("darkgreen", "orange")) +
  scale_fill_manual(values = c("darkgreen", "orange"))
```







```{r}
effects::Effect(focal.predictors = c("female", "educate"),
                mod = glm_possion_2,
                xlevels = list(educate = seq(from = 0,
                                             to   = 20,
                                             by = .1),
                               income = 11)) %>%          #Median Income
  data.frame() %>% 
  ggplot(aes(x = educate,
             y = fit,
             group = female)) +
  geom_ribbon(aes(ymin = fit - se,  # bands = +/- 1 SEM
                  ymax = fit + se),
              alpha = .2) +
  geom_line(aes(linetype = female),
            size = 1) +
  theme_bw() +
  labs(x = "Education, Years",
       y = "Predicted Mean Number of Volunteer Activities",
       color = NULL,
       fill = NULL,
       linetype = NULL) +
  theme(legend.position = c(0, 1),
        legend.justification = c(-.1, 1.1),
        legend.background = element_rect(color = "black"),
        legend.key.width = unit(2, "cm")) +
  scale_linetype_manual(values = c("solid", "longdash"))
```


## Negative Binomial Regression

### Multiple Predictors

#### Fit the model

```{r}
glm_negbin_1 <- MASS::glm.nb(volteer ~ female + nonwhite + educate + income,
                             data = data_gss)

summary(glm_negbin_1)
```

> Note: the deviance residuals all have absolute values less than 3-4'ish...better than before


**Theta in R = 1/alpha in Stata**

```{r, results='asis'}
# Hoffmann Example 6.5
texreg::knitreg(list(glm_possion_2, 
                       texreghelpr::extract_glm_exp(glm_possion_2,
                                                    include.aic = FALSE,
                                                    include.bic = FALSE,
                                                    include.loglik = FALSE,
                                                    include.deviance = FALSE,
                                                    include.nobs = FALSE)),
                  custom.model.names = c("b (SE)", "IRR [95% CI]"),
                  custom.coef.map = list("(Intercept)" ="Intercept",
                                         femalefemale = "Female vs. Male",
                                         "nonwhitenon-white" = "Non-white vs. White",
                                         educate = "Education, years",
                                         income = "Income, 1000's"),
                  caption = "GLM: Multiple Possion Regression",
                  single.row = TRUE,
                  digits = 3)
```


#### Predictions


> Note: These means are on the original scale (number of volunteer activities in the past year).  These standard errors are called "delta-method standard errors"

```{r}
effects::Effect(focal.predictors = c("female"),
                mod = glm_negbin_1,
                xlevels = list(nonwhite = "non-white",
                               educate = 5,
                               income = 12)) %>% 
  data.frame()
```

```{r}
ggeffects::ggemmeans(model = glm_negbin_1,
                     terms = c("female"),
                     condition = c(nonwhite = "white",
                                   educate = 12,
                                   income = 5))
```


Compare to the Poisson:

```{r}
ggeffects::ggemmeans(model = glm_possion_2,
                     terms = c("female"),
                     condition = c(nonwhite = "white",
                                   educate = 12,
                                   income = 5))
```

Note: The predictions are very similar for Poisson and Negative Binomial...therefor the overdisperssion does not affect the sex difference much, but it may affect other things... 




#### Parameter Estimates

Coefficients are in terms of the **LOG of** the number of times a person volunteers per year.

```{r}
glm_negbin_1 %>% coef()
```

Exponentiating the coefficients (betas) returns the values to the original scale (number of times a person volunteers per year) and is refered to as the **incident rate ratio IRR**.

```{r}
glm_negbin_1 %>% coef() %>% exp()
```



```{r, results='asis'}
texreg::knitreg(list(glm_negbin_1, 
                       texreghelpr::extract_glm_exp(glm_negbin_1,
                                                    include.aic = FALSE,
                                                    include.bic = FALSE,
                                                    include.loglik = FALSE,
                                                    include.deviance = FALSE,
                                                    include.nobs = FALSE)),
                  custom.model.names = c("b (SE)", "IRR [95% CI]"),
                  custom.coef.map = list("(Intercept)" ="Intercept",
                                         femalefemale = "Female vs. Male",
                                         "nonwhitenon-white" = "Non-white vs. White",
                                         educate = "Education, Years",
                                         income = "Income"),
                  caption = "GLM: Negitive Binomial Regression",
                  single.row = TRUE,
                  digits = 3)
```



#### Residual Diagnostics


```{r}
par(mfrow = c(2, 2))
plot(glm_negbin_1)
par(mfrow = c(1, 1))
```

These still don't look very good :(


#### Compare models

```{r}
performance::compare_performance(glm_possion_2, glm_negbin_1, rank = TRUE)
```




## Zero Inflated Poisson


#### Fit the model

```{r}
glm_zip_1 <- pscl::zeroinfl(volteer ~ female + nonwhite + educate + income | educate,
                               data = data_gss)

summary(glm_zip_1)
```



```{r}
glm_zip_1 %>% coef() %>% exp()
```



> Compares two models fit to the same data that do not nest via Vuong's non-nested test.

```{r}
pscl::vuong(glm_zip_1, glm_possion_2)
```




## Zero Inflated Negative Binomial


#### Fit the model

```{r}
glm_zinb_1 <- pscl::zeroinfl(volteer ~ female + nonwhite + educate + income | educate,
                               data = data_gss,
                             dist = "negbin")

summary(glm_zinb_1)
```



```{r}
glm_zinb_1 %>% coef() %>% exp()
```

```{r}
pscl::vuong(glm_zinb_1, glm_negbin_1)
```


```{r}
pscl::vuong(glm_zip_1, glm_zinb_1)
```

 The 'best' model is the zero-inflated negative binomial
